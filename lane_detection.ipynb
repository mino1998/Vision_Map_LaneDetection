{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K17oSFA_ui4u"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#구글드라이브연동"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "FSTb6QF2uwUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_region_of_interest(img, vertices):\n",
        "    '''\n",
        "    영상에서 관심 영역만 남김\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    img: array\n",
        "        적용할 타겟 영상\n",
        "    vertices: list of points\n",
        "        관심 영역의 좌표점들이 저장된 리스트\n",
        "    '''\n",
        "    mask = np.zeros_like(img)\n",
        "    cv2.fillPoly(mask, vertices, 255)\n",
        "\n",
        "    return cv2.bitwise_and(img, mask)\n",
        "\n",
        "def full_pipeline(img):\n",
        "    '''\n",
        "    차선 검출을 위한 전체 파이프라인 코드\n",
        "    '''\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    vertices = np.array([[(50,height),\n",
        "                          (width/2-45, height/2+60),\n",
        "                          (width/2+45, height/2+60),\n",
        "                          (width-50,height)]],\n",
        "                        dtype=np.int32)\n",
        "\n",
        "\n",
        "    ## 1) 명암 영상에서 엣지 정보를 찾기 위해 영상의 색 공간 변환\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    ## 2) (optional) 영상 내의 노이즈를 감소시키기 위해 스무딩 효과 적용 (cv2.Canny()에 구현되어있지 않음)\n",
        "    blur_img = cv2.GaussianBlur(gray_img, (3, 3), 0)\n",
        "\n",
        "    ## 3) Canny edge detection을 사용하여 엣지 영상 검출\n",
        "    edge_img = cv2.Canny(blur_img,\n",
        "                         threshold1=70,   # gradient의 강도 < threshold1인 경우 무조건 엣지가 아니라고 판단\n",
        "                         threshold2=175)  # gradient의 강도 > threshold2인 경우 무조건 엣지라고 판단(강한 엣지)\n",
        "                                          # threshold1 < gradient의 강도 < threshold2인 경우 강한 엣지와 연결되어 있는 경우에만 엣지라고 판단\n",
        "\n",
        "    ## 4) 타겟 차선 이외 부분에서의 엣지는 고려하지 않기 위해 영상에서 관심 영역만 남김\n",
        "    roi_img = set_region_of_interest(edge_img, vertices)\n",
        "\n",
        "    ## 5) Hough transform을 사용하여 조건을 만족하는 직선을 모두 검출\n",
        "    lines = cv2.HoughLinesP(roi_img,\n",
        "                            rho=1,            # rho값의 범위 (0~1 실수)\n",
        "                            theta=np.pi/180,  # theta값의 범위(0~180 정수)\n",
        "                            threshold=10,     # 변환 공간에서 만나는 점의 개수 기준\n",
        "                            minLineLength=15, # 직선이 만족해야하는 최소 길이\n",
        "                            maxLineGap=5)     # 얼마만큼 떨어져 있어도 하나의 직선으로 볼 것인지\n",
        "\n",
        "    # ## 6) 찾은 직선을 결과 영상에 그리기\n",
        "    # result = np.copy(img)\n",
        "    # for line in lines:\n",
        "    #     for x1,y1,x2,y2 in line:\n",
        "    #         cv2.line(result, (x1, y1), (x2, y2), color=(0,0,255), thickness=5)\n",
        "\n",
        "    ## 6) 찾은 직선을 결과 영상에 그리기\n",
        "    result = np.copy(img)\n",
        "    if lines is not None:  # lines가 None이 아닌 경우에만 반복\n",
        "      for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            cv2.line(result, (x1, y1), (x2, y2), color=(0,0,255), thickness=5)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "GJTGsZ3du-l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_check_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"{image_path} 이미지를 불러오는 데 실패했습니다. 파일 경로를 확인해 주세요.\")\n",
        "    else:\n",
        "        print(f\"{image_path} 이미지가 성공적으로 불러와졌습니다.\")\n",
        "    return image\n",
        "\n",
        "# 이미지 파일 경로\n",
        "solidWhiteRight_path = '/content/drive/MyDrive/myproject/lane/solidWhiteRight.jpg'\n",
        "solidYellowLeft_path = '/content/drive/MyDrive/myproject/lane/solidYellowLeft.jpg'\n",
        "\n",
        "# 이미지 로드 및 확인\n",
        "solidWhiteRight = load_and_check_image(solidWhiteRight_path)\n",
        "solidYellowLeft = load_and_check_image(solidYellowLeft_path)"
      ],
      "metadata": {
        "id": "eBEwy4wYwMva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 이미지 로드 및 확인\n",
        "solidWhiteRight = load_and_check_image(solidWhiteRight_path)\n",
        "solidYellowLeft = load_and_check_image(solidYellowLeft_path)\n",
        "\n",
        "listOfFiles = [solidWhiteRight, solidYellowLeft]\n",
        "\n",
        "for i, img in enumerate(listOfFiles):\n",
        "    if img is None:\n",
        "        continue  # 이미지가 None인 경우, 즉 로드에 실패한 경우 다음 이미지로 넘어감\n",
        "\n",
        "    result = full_pipeline(img)\n",
        "    cv2_imshow(result)  # cv2.imshow 대신 cv2_imshow 사용\n",
        "    cv2.imwrite(f'lane_detection_{i}.jpg', result)  # 각 이미지에 대한 결과를 별도의 파일로 저장\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "s3iSmu25vEwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동영상 파일 열기\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/myproject/lane/lane.mp4')\n",
        "\n",
        "# 원본 동영상의 프레임 레이트와 해상도 가져오기\n",
        "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# 결과 동영상을 저장하기 위한 준비\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, frame_rate, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 차선 검출\n",
        "    result = full_pipeline(frame)\n",
        "\n",
        "    # 결과 프레임을 동영상 파일에 쓰기\n",
        "    out.write(result)\n",
        "\n",
        "# 자원 해제\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "FA-HZMHIxAOD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}